---
prev:
    text: § 8. Метод Зейделя
    link: ../05/
next:
    text: § 10. Матрицы специального вида
    link: ../07/
---

**Тема 2. Приближённые методы решения СЛАУ**

# § 9. Число обусловленности матрицы. Погрешности решений СЛАУ. Две теоремы о погрешностях

Предположим, что в исходные данные (матрицу и свободные члены СЛАУ) внесено некоторое возмущение (вместо $A$ имеем $A + \delta A$, вместо $\bar{b}$ имеем $\bar{b} + \delta \bar{b}$ и, следовательно, вместо $\bar{x}$ имеем $\bar{x} + \delta \bar{x}$).

В качестве относительной погрешности решения будем рассматривать величину ${ ||\delta \bar{x}|| \over ||\bar{x}|| }$.

:::: info Теорема 1
Пусть $\delta A = 0$. Тогда для возмущённой задачи
$$
A(\bar{x} + \delta \bar{x}) = \bar{b} + \delta \bar{b} \tag{∗}
$$
справедливо неравенство
$$
{ ||\delta \bar{x}|| \over ||\bar{x}|| } \le ||A|| \cdot ||A^{-1}|| \cdot { ||\delta \bar{b}|| \over ||\bar{b}|| }.
$$

::: details Доказательство
Раскроем скобки в системе $(∗)$, учитывая, что $A\bar{x} = \bar{b}$. Получим $A\delta \bar{x} = \delta \bar{b}$, т. е. $\delta \bar{x} = A^{-1} \delta \bar{b}$.

Далее перейдём к нормам:
$$
||\delta\bar{x}|| = ||A^{-1} \delta \bar{b}|| \le ||A^{-1}|| \cdot ||\delta \bar{b}||.
$$

Т. к. $\bar{b} = A\bar{x}$, то
$$
||\bar{b}|| = ||A\bar{x}|| \le ||A|| \cdot ||\bar{x}||.
$$

Умножим одно неравенство на другое и получим требуемый результат:
$$
{1 \over ||\bar{x}||} \le { ||A|| \over ||\bar{b}|| }. ~ ~ ~ ~ \blacksquare
$$
:::

::::

:::: info Теорема 2
Пусть $\delta \bar{b} = 0$. Тогда для возмущённой системы
$$ (A + \delta A)(\bar{x} + \delta \bar{x}) = \bar{b} \tag{∗∗} $$
справедливо неравенство

$$
{ ||\delta \bar{x}|| \over ||\bar{x} + \delta \bar{x}|| } \le ||A|| \cdot ||A^{-1}|| \cdot { ||\delta A|| \over ||A|| },
$$
где первая дробь — это отношение погрешностей решения, а вторая дробь — относительная погрешность исходных данных.

::: details Доказательство
Раскроем скобки в $(∗∗)$, учитывая, что $A\bar{x} = \bar{b}$. Получим
$$
A \delta \bar{x} = -\delta A (\bar{x} + \delta \bar{x}).
$$

Умножим на $-A^{-1}$:
$$
-\delta \bar{x} = A^{-1} \cdot \delta \cdot A \cdot (\bar{x} + \delta \bar{x}).
$$

Перейдём к нормам:
$$
||\delta\bar{x}|| = ||A^{-1} \delta A (\bar{x} + \delta \bar{x})|| \le
$$
$$
\le ||A^{-1}|| \cdot ||\delta A|| \cdot ||\bar{x} + \delta \bar{x}||.
$$

Делим и умножаем неравенство на $||A||$, получаем утверждение теоремы. $\blacksquare$
:::

::::

<br>

::: info Определение
Коэффициент пропорциональности между погрешностями результатов и исходных данных, присутствующий в обоих результатах, называется **числом обусловленности:**
$$
\text{cond} ~ A = ||A^{-1}|| \cdot ||A||.
$$
:::

Свойства числа обусловленности:

1. Очевидно, что выражение для числа обусловленности связано с вычислением нормы матрицы.

   В случае с симметричной матрицей
   $$
   ||A||_3 = \underset{i}{\max} |\lambda_i| \implies ||A^{-1}||_3 = \underset{i}{\max} \left|{ 1 \over \lambda_i }\right| = {1 \over \underset{i}{\min} |\lambda_i|} \implies
   $$
   $$
   \implies \text{cond} ~ A = { \underset{i}{\max} |\lambda_i| \over \underset{i}{\min} |\lambda_i| }.
   $$

2. Матрица называется **плохо определённой**, если её определитель близок к нулю. В этом случае можно умножить обе части СЛАУ на достаточно большое число.

   В случае плохой обусловленности это не помогает, т. к.
   $$
   \text{cond} ~ (cA) = ||(cA)^{-1}|| \cdot ||cA|| = $$
   $$ = {1 \over |c|} \cdot ||A^{-1}|| \cdot |c| \cdot ||A|| = \text{cond} ~ A,
   $$
   где $c = \text{const}$.

3. $$
   \text{cond} ~ A = ||A^{-1}|| \cdot ||A|| \ge ||A^{-1} \cdot A|| = ||E|| = 1.
   $$
   Таким образом, все матрицы можно поделить на *плохо обусловленные* и *хорошо обусловленные*.

   Хорошо обусловленные матрицы имеют число обусловленности, близкое к единице. Плохо обусловленные — большое число обусловленности.

4. Число обусловленности от произведения:
   $$
   \text{cond} ~ (AB) = ||(AB)^{-1}|| \cdot ||AB|| = ||B^{-1} \cdot A^{-1}|| \cdot ||AB|| \le
   $$
   $$
   \le ||B^{-1}|| \cdot ||A^{-1}|| \cdot ||A|| \cdot ||B|| = \text{cond} ~ A \cdot \text{cond} ~ B.
   $$

   Таким образом, поскольку число обусловленности матрицы всегда не меньше единицы, то умножением матрицы на другую его не улучшить.


::: info Пример
Пусть требуется решить систему

$$\begin{cases}
x_1 + 0,99x_2 = 1,99; \\
0,99x_1 + 0,98x_2 = 1,97.
\end{cases}$$

Очевидно, что решением является $(1; 1)$.

Внесём возмущение в правую часть:

$$\begin{cases}
x_1 + 0,99x_2 = 1,98; \\
0,99x_1 + 0,98x_2 = 1,96.
\end{cases}$$

В данном случае решением будет $(0; 2)$.

Получается, что
$$
\delta \bar{b} = \left(\begin{matrix} -0,01 \\ -0,01 \end{matrix}\right),
~ ~ ~ ~
\bar{b} \approx \left(\begin{matrix} 2 \\ 2 \end{matrix}\right),
$$
$$
{ \delta \bar{b} \over ||\bar{b}|| } = -\left(\begin{matrix} 0,005 \\ 0,005 \end{matrix}\right) \approx 0,5\%.
$$

Что касается $\bar{x}$, то

$$
\delta \bar{x} = \left(\begin{matrix} 1 \\ 1 \end{matrix}\right),
$$
$$
{ \delta \bar{x} \over ||\bar{x}|| } = \left(\begin{matrix} -1 \\ 1 \end{matrix}\right) \approx 100\%.
$$

(вроде ничтожное изменение исходных данных может привести к сильному изменению решения)

Найдём обратную матрицу:

$$
A^{-1} = \left(\begin{matrix} -9800 & 9900 \\ 9900 & -10000 \end{matrix}\right).
$$

Её число обусловленности:
$$
\text{cond} ~ A = ||A^{-1}||_1 \cdot ||A||_1 = 19900 \cdot 1,99 \approx 40000.
$$

или

$$\begin{cases}
x_1 + 0,99x_2 = 2; \\
0,99x_1 + 0,98x_2 = 1,98.
\end{cases}$$

Очевидно, что решением является $(2; 0)$.
:::

