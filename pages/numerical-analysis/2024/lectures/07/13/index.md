---
prev:
    text: § 12. Средние квадратические приближения. Основная теорема
    link: ../12/
next:
    text: § 14. Системы ортогональных многочленов
    link: ../14/
---

**Тема 7. Средние квадратические приближения**

# § 13. Метод наименьших квадратов (МНК)

Рассмотрим случай, когда множество $x \in F = \set{x_i}_{i = \overline{0,m}}$ дискретно, и функция $f(x)$ задана на нём табличным способом ($y = f(x)$).

Предположим, что поставленная задача о приближении полученных экспериментальных данных некоторой теоретической зависимостью, общий вид которой известен из физического смысла задачи.

Предполагается, что эта зависимость имеет набор параметров $a_0, a_1, ..., a_n$, которые надо подобрать так, чтобы теоретические и экспериментальные данные отличались наименьшим образом.

Пусть данная зависимость имеет вид $y = F(x, a_0, a_1, ..., a_n)$. Тогда в качестве меры отклонения теории от практики используется величина

$$
\sigma = \sum_{i=0}^m \left( F(x, a_0, a_1, ..., a_n) - y_i \right)^2
$$

(сумма квадратов отклонений по всем узлам).

Если $F$ имеет достаточно гладкую зависимость от своих параметров, то можно поставить задачу на экстремум (минимум) для функции $\sigma$:

$$
\sigma \xrightarrow[a_0, ..., a_n]{} \min.
$$

Как известно, необходимое условие экстремума выглядит так:

$$
{\partial \sigma \over \partial a_0} = 0, ~ ~
{\partial \sigma \over \partial a_1} = 0, ~ ~
..., ~ ~
{\partial \sigma \over \partial a_n} = 0.
\tag{∗}
$$

В общем случае получаем систему нелинейных уравнений.

Рассмотрим теперь случай, когда теоретическая кривая $F$ явялется обобщённым многочленом:

$$
F = \sum_{j=0}^n a_j \varphi_j (x).
$$

Тогда система уравнений $(∗)$ примет вид

$$
{\partial \sigma \over \partial a_k} =
\sum_{i=0}^m 2 \left(
    \sum_{j=0}^n a_j \varphi_j (x_i) - y_i
\right) \varphi_k (x_i) = 0,
$$

где $k = \overline{0, n}$.

Сократим на $2$ и переставим местами суммирование:

$$
\sum_{j=0}^n a_j \sum_{i=0}^m \varphi_j (x_i) \varphi_k (x_i) =
\sum_{i=0}^m y_i \varphi_k (x_i) = \sum_{i=0}^m f(x_i) \varphi_k (x_i).
$$

Мы получаем СЛАУ, которая полностью совпадает со СЛАУ для МНСП, т. к.

$$
(\varphi_j, \varphi_k) = \sum_{i=0}^m \varphi_j(x_i) \varphi_k(x_i),
$$

$$
(f, \varphi_k) = \sum_{i=0}^m f(x_i) \varphi_k (x_i).
$$