---
prev:
    text: 5. Классическая модель множественной линейной регрессии
    link: ../05/
next: false
---

**Математические модели в экономике**

# 6. Нелинейные модели

<p class="subtext">Лекция</p>

## Нелинейные формы зависимости

Использование лишь линейных зависимостей для описания экономических взаимосвязей часто оказывается недостаточным. Необходимо использовать и нелинейные соотношения.

Например, *производственная функция Кобба-Дугласа:*

$$
Y = A \cdot K^\alpha \cdot L^\beta,
$$

где $Y$ — выпуск, $K$ — затраты капитала, $L$ — затраты труда; $A$, $\alpha$, $\beta$ — параметры.

:::: info Пример
По исходным данным оценить коэффициенты $A$, $\alpha$, $\beta$ в формуле Кобба-Дугласа

$$
Y = A \cdot K^\alpha \cdot L^\beta \cdot (1 + \varepsilon).
$$

| $Y$ | $K$ | $L$ |
|-|-|-|
| 34 | 2 | 4 |
| 53 | 3 | 6 |
| 81 | 5 | 7 |
| 81 | 5 | 7 |
| 113 | 7 | 9 |
| 97 | 9 | 4 |

::: info Решение
Логарифмированием зависимость приводится к линейному виду:

$$
\ln Y = \ln A + \alpha \cdot \ln K + \beta \cdot \ln L + \ln (1 + \varepsilon).
$$

| $\ln Y$ | $\ln K$ | $\ln L$ |
|-|-|-|
| 3,53 | 0,69 | 1,39 |
| 3,96 | 1,1 | 1,79 |
| 4,39 | 1,61 | 1,95 |
| 4,39 | 1,61 | 1,95 |
| 4,73 | 1,95 | 2,2 |
| 4,57 | 2,2 | 1,39 |

Далее как обычно:

$$
\begin{pmatrix}
\ln A \\ \alpha \\ \beta
\end{pmatrix} =
\begin{pmatrix}
2,48 \\ 0,69 \\ 0,41
\end{pmatrix}.
$$

$$
\ln Y = 2,48 + 0,69 \cdot \ln K + 0,41 \cdot \ln K.
$$

$$
A = e^{2,48} \approx 12.
$$

**Ответ:** $Y = 12 \cdot K^{0,69} \cdot L^{0,41} \cdot (1 + \varepsilon)$.
:::
::::

:::: info Пример (полиномиальная зависимость)
По исходным данным оценить коэффициенты в формуле

$$
y = a + bx + cx^2.
$$

| $y$ | $x$ |
|-|-|
| 5 | 2 |
| 3 | 3 |
| 3 | 5 |
| 2 | 5 |
| 2 | 7 |
| 1 | 8 |

::: info Решение
Заменой $z = x^2$ зависимость приводится к линейному виду $y = a + bx + cz$.

| $y$ | $x$ | $z = x^2$ |
|-|-|-|
| 5 | 2 | 4 |
| 3 | 3 | 9 |
| 3 | 5 | 25 |
| 2 | 5 | 25 |
| 2 | 7 | 49 |
| 1 | 8 | 64 |

Далее как обычно:

$$
\begin{pmatrix}
a \\ b \\ c
\end{pmatrix} =
\begin{pmatrix}
6,54 \\ -1,11 \\ 0,06
\end{pmatrix}.
$$

$$
Y = 6,54 - 1,11 X + 0,06 Z.
$$

**Ответ:** $y = 6,54 - 1,11 x + 0,06 x^2$.
:::
::::

::: info Пример
В таблице перечислены некоторые модели мотоциклов, их пробег (в километрах на литр) и вес (в килограммах).

| Motorcycle | Mileage | Dry Weight |
|-|-|-|
| RSV Mille | 16,77 | 220,5 |
| RSV Tuono | 17,2 | 214,2 |
| Mana 850 | 21,07 | 232,2 |
| R1150RS | 17,2 | 261,9 |
| K1200GT | 16,34 | 299,7 |
| R1200GS | 19,78 | 261,9 |
| CBR600RR | 15,48 | 193,05 |
| ST1300 | 16,77 | 328,95 |
| CBR300R | 23,64 | 161,55 |
| Ninja 300 | 25,8 | 173,7 |

<figure>
    <img src="/media/images/mme_05_10.png" />
</figure>

Добавим линию тренда.

Линия тренда по умолчанию линейная, однако в диалоговом окне "Линия тренда" есть возможность добавить другие тренды. Мы выберем "Полиномиальную". Как только мы выберем "Полиномиальный", рядом с ним появится поле "Порядок", и мы сможем установить порядок нужного уравнения.

<figure>
    <img src="/media/images/mme_06_01.png" />
</figure>
<br />
<figure>
    <img src="/media/images/mme_06_02.png" />
</figure>

Здесь выбрано уравнение регрессии третьей степени.
:::

:::: info Пример (гиперболическая зависимость)
По исходным данным оценить коэффициенты в формуле

$$
y = a + {b \over x} + \varepsilon.
$$

| $y$ | $x$ |
|-|-|
| 5 | 2 |
| 3 | 3 |
| 3 | 5 |
| 2 | 5 |
| 2 | 7 |
| 1 | 8 |

::: info Решение
Заменой $z = {1 \over x}$ зависимость приводится к линейному виду $y = a + bz + \varepsilon$.

| $y$ | $z = {1 \over x}$ |
|-|-|
| 5 | 0,5 |
| 3 | 0,3333 |
| 3 | 0,2 |
| 2 | 0,2 |
| 2 | 0,14286 |
| 1 | 0,125 |

Далее как обычно:

$$
y = 0,43 + 8,94 z + \varepsilon.
$$

**Ответ:** $y = 0,43 + {8,94 \over x} + \varepsilon$.
:::
::::

## Нелинейные модели, не приводимые к линейному виду

Всё же далеко не всякую зависимость заменой переменных можно привести к линейному виду.

В общем случае уравнение нелинейной регрессии с аддитивным случайным членом $\varepsilon$ имеет вид

$$
y = f(x_1, ..., x_m, \beta_0, ..., \beta_k) + \varepsilon,
$$

где $\beta_0, ..., \beta_k$ — параметры модели.

Для нахождения оценок параметров можно использовать, как и в линейном случае, **метод наименьших квадратов**, но не матричную формулу $(∗)$.

$$
ESS = \sum_{i=1}^n e_i^2 = \sum_{i=1}^n (y_i - \hat{y}_i)^2 \to \min
$$

:::: info Пример
По исходным данным оценить коэффициенты $a$, $b$ в формуле

$$
y = a \cdot e^{bx} + \varepsilon.
$$

| $y$ | $x$ |
|-|-|
| 2 | 1 |
| 9 | 2 |
| 47 | 3 |

::: info Решение
Задача не сводится к линейной.

Выпишем формулу для ESS:

$$
ESS = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = (2 - ae^b)^2 + (9 - ae^{2b})^2 + (47 - ae^{3b})^2.
$$

Нужно найти *минимум* этой функции. Используем надстройку *Поиск решения* из MS Excel. Внесём все данные и формулы в таблицу:

<figure>
    <img src="/media/images/mme_06_03.png" />
</figure>

Начальные значения $a$ и $b$ положены равными нулю.

Вызовем надстройку *Поиск решения* и введём данные в диалоге.

<figure>
    <img src="/media/images/mme_06_04.png" />
</figure>

Таким образом, оценки параметров модели: $a = 0,34$, $b = 1,642$.

$$
y = 0,34 \cdot e^{1,642 x} + \varepsilon.
$$
:::
::::

Важно понимать, что не существует правил относительно линейных и нелинейных моделей.

В целом, лучше всегда начинать с линейной модели, а затем проверить её пригодность. После этого вы можете построить нелинейную модель на тех же данных и проверить её соответствие, чтобы увидеть, улучшилось ли оно. Если нелинейная модель значительно улучшает подгонку по сравнению с линейной моделью, то лучше использовать нелинейную модель.

Выбор между линейной и нелинейной моделями для данного набора данных — это компромисс между соответствием модели (что влияет на точность прогноза, сделанного на основе модели) и сложностью построения и анализа.

## Спецификация модели

Спецификация модели включает следующие этапы:

1. отбор факторов;
2. выбор функциональной формы модели.

### Отбор факторов

Нередко имеется большое число факторов, но неясно, какие именно переменные включать в модель. В этом случае используются различные **эвристические процедуры**.

Далее приведён простой пример такой процедуры.

::: tip Замечание
При добавлении в модель новых объясняющих переменных коэффициент $R^2$ *не может уменьшиться*. Поэтому *при добавлении новой переменной* неясно, за счёт чего возрос $R^2$: за счёт реального влияния дополнительной переменной или просто из-за возрастания числа переменных.

Для того чтобы можно было как-то *сравнивать модели с разным числом переменных*, вводят так называемый **скорректированный** (или **нормированный**) **коэффициент детерминации:**

$$
R^2_\text{норм} = 1 - { ESS / (n - m - 1) \over TSS / (n - 1) }
$$

Это число также не превосходит 1, но в некоторых случаях может оказаться и отрицательным.
:::

**Процедура пошагового отбора независимых переменных:**

1. Из исходного набора переменных включается в модель переменная, имеющая *наибольший по модулю коэффициент корреляции с зависимой переменной $Y$*.
2. На каждом последующем шаге в модель добавляется та из переменных, добавление которой *максимально увеличивает скорректированный коэффициент детерминации*.
3. Если добавление новых переменных не увеличивает этот коэффициент, процедура считается завершённой.

:::: info Пример
Произвести пошаговый отбор переменных регрессии для выборки.

| $Y$ | $X_1$ | $X_2$ | $X_3$ | $X_4$ |
|-|-|-|-|-|
| 15 | 1 | 17 | 41 | 31 |
| 27 | 4 | 11 | 41 | 10 |
| 32 | 7 | 4 | 22 | 8 |
| 31 | 8 | 8 | 37 | 9 |
| 36 | 10 | 8 | 46 | 17 |
| 50 | 12 | 7 | 43 | 8 |
| 23 | 11 | 11 | 41 | 10 |
| 16 | 5 | 14 | 34 | 5 |
| 52 | 19 | 7 | 50 | 7 |
| 19 | 23 | 5 | 15 | 6 |

::: info Решение
1. Найдём матрицу корреляций:
   
   <figure>
       <img src="/media/images/mme_06_05.png" />
   </figure>

   Наибольший *по модулю* коэффициент корреляции с $Y$ имеет переменная $X_2$.

2. Строим регрессию $Y$ на $X_2$:

   $$
   y = 46,75 - 1,81 x_2, ~~ R^2_\text{корр} = 0,232.
   $$

3. Будем добавлять к $X_2$ каждую из переменных $X_1$, $X_3$, $X_4$:

   1. Добавим к $X_2$ переменную $X_1$:

      $$
      (X_2; X_1): ~~~ y = 46,21 + 0,027 x_1 - 1,78 x_2, ~~ R^2_\text{корр} = 0,122.
      $$
   2. Теперь вариант $(X_2; $X_3)$:
      $$
      y = \cdots, ~~ R^2_\text{корр} = 0,852.
      $$
   3. Наконец, вариант $(X_2; X_4)$:
      $$
      y = \cdots, ~~ R^2_\text{корр} = 0,126.
      $$

   $R^2_\text{корр}$ сильнее возрос в варианте $(X_2; X_3)$. Оставляем эти переменные.

4. Добавим к $(X_2; X_3)$ другие переменные:

   1. Добавим к этому варианту $(X_2; X_3)$ переменную $X_1$:

      $$
      (X_2; X_3; X_1): ~~~ y = \cdots, ~~ R^2_\text{корр} = 0,828.
      $$

      $R^2_\text{корр}$ уменьшился по сравнению с предыдущим вариантом.

   2. Добавим к варианту $(X_2; X_3)$ переменную $X_4$:

      $$
      (X_2; X_3; X_4): ~~~ y = \cdots, ~~ R^2_\text{корр} = 0,829.
      $$

   Все варианты с тремя переменными оказались *хуже*, чем вариант с двумя переменными $(X_2; X_3)$. Отбор переменных закончен.

**Ответ:** результат пошагового отбора переменных

$$
y = 19,59 - 2,8 x_2 + 0,98 x_3, ~~~ R^2_\text{корр} = 0,852.
$$
:::
::::

## Проверка гипотезы о линейной связи коэффициентов

Пусть рассматривается линейная модель

$$
y = \beta_0 + \beta_1 x_1 + \cdots + \beta_m x_m + \varepsilon.
\tag{U}
$$

Мы хотим провериь гипотезу:

> $H_0$: коэффициенты модели удовлетворяют $q$ линейным ограничениям.

Вот, например, три ограничения ($q = 3$):

$$
H_0: ~~ \begin{cases}
\beta_1 = 2 \beta_2, \\
\beta_3 = 0, \\
\beta_4 = 5.
\end{cases}
$$

Чтобы проверить такую гипотезу, нужно:

1. Вычислить $ESS_U$ для исходной регрессии.
2. Вычислить $ESS_R$ для регрессии, в которой выполнены ограничения.
3. Вычислить

   $$
   F = { (ESS_R - ESS_U) / q \over ESS_U / (n - m - 1) }
   $$

Гипотеза $H_0$ об ограничениях *принимается*, если

$$
F < F_{1 - \alpha}(q, n - m - 1).
$$

::: info Пример на Python
Набор данных о ценах на жильё в Калифорнии. Построим линейную регрессионную модель, которая предсказывает цену на жильё в зависимости от нескольких факторов.

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn.datasets import fetch_california_housing

# Загрузка данных о жилье в Калифорнии
california = fetch_california_housing()

# Преобразование в DataFrame
df = pd.DataFrame(california.data, columns=california.feature_names)

# Добавление зависимой переменной (цены на жильё)
df['MedHouseVal'] = california.target

# Просмотр первых строк данных
df.head()
```

Первые 20 строк данных:
:::